import java.time.LocalDateTime
import java.time.format.DateTimeFormatter

import com.cpc.spark.common.Utils

object HourlyCalibration {
  def main(args: Array[String]): Unit = {
    // parse and process input
    val endDate = args(0)
    val endHour = args(1)
    val hourRange = args(2).toInt
    val softMode = args(3).toInt


    val endTime = LocalDateTime.parse(s"$endDate-$endHour", DateTimeFormatter.ofPattern("yyyy-MM-dd-HH"))
    val startTime = endTime.minusHours(Math.max(hourRange - 1, 0))

    val startDate = startTime.format(DateTimeFormatter.ofPattern("yyyy-MM-dd"))
    val startHour = startTime.format(DateTimeFormatter.ofPattern("HH"))

    println(s"endDate=$endDate")
    println(s"endHour=$endHour")
    println(s"hourRange=$hourRange")
    println(s"startDate=$startDate")
    println(s"startHour=$startHour")
    println(s"softMode=$softMode")

    // build spark session
    val sparkSession = Utils.buildSparkSession("hourlyCalibration")

    // get union log
    val log = sparkSession.sql(
      s"select isclick, ext['exp_ctr'].int_value as ectr, show_timestamp, exptags from dl_cpc.cpc_union_log" +
        "where `date`>='$startDate' and hour >= '$startHour' and `date` <= $endDate and hour <= $'endHour'" +
        "and media_appsid in ('80000001', '80000002') and isshow = 1 and ext['antispam'].int_value = 0" +
        "and ideaid > 0 and adsrc = 1 and adslot_type in (1) AND userid > 0")

    val modeledLog = log.rdd.map( x => {
      val isClick = x.getAs[Int]("isclick").toDouble
      val ectr = x.getAs[Int]("ectr").toDouble / 1e6
      // not used right now in the first version, will be used for weighting later
//      val showTimeStamp = x.getAs[Int]("show_timestamp")
      val model = Utils.getCtrModelIdFromExpTags(x.getAs[String]("exptags"))
      (model, isClick, ectr, 1)
    }).groupBy(x => x(0)).aggregate()



  }
}